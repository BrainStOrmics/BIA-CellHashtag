{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from cellhashtag.utils import *\n",
    "from cellhashtag._Agent import CellHashtagAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bgi_api_key = 'sk-NYPE5WNGTK781Nox801a5934A9F84a03BfC525359eBaE7B6'\n",
    "bgi_api_base = 'http://10.224.28.80:3000/v1'\n",
    "def call_chatllm_openai(api_key, api_base, model_name):\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key = api_key,\n",
    "        openai_api_base=api_base,\n",
    "        model = model_name)\n",
    "    return llm\n",
    "chat_llm = call_chatllm_openai(bgi_api_key, bgi_api_base, 'deepseek-v3-hs')\n",
    "think_llm = call_chatllm_openai(bgi_api_key, bgi_api_base, 'deepseek-v3-hs')\n",
    "\n",
    "tavily_api = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perpare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('../cellhashtag/data/example.h5ad')\n",
    "cell_markers_df = pd.read_csv('../cellhashtag/data/example_cellmarkers.csv',index_col=0)\n",
    "print('Check cell markers dataframe:')\n",
    "cell_markers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CellHashtagAgent(web_scraper_api_key = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(agent.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(agent.subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_adata, output_states = agent.run(\n",
    "                                        llm=think_llm, \n",
    "                                        adata= adata,\n",
    "                                        cell_marker_df_dir = '../cellhashtag/data/example_cellmarkers.csv',\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cluster(dataframe,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv(\"AnnoResDF.csv\",index_col=0)\n",
    "res_df['cluster'] = res_df['cluster'].astype(str)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = res_df.copy().set_index('cluster')\n",
    "anno_dic_raw = temp_df['cell type'].to_dict()\n",
    "anno_dic= temp_df['norm. cell type'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dic_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"Cell#\"] = adata.obs[\"leiden\"]\n",
    "adata.obs[\"Cell#\"] = adata.obs[\"Cell#\"].map(anno_dic)\n",
    "adata.obs[\"Cell#_raw\"] = adata.obs[\"leiden\"]\n",
    "adata.obs[\"Cell#_raw\"] = adata.obs[\"Cell#_raw\"].map(anno_dic_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'umap' not in adata.uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata,color = ['Cell#','Cell#_raw','leiden'],ncols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['cluster'] = res_df['cluster'].astype(str)\n",
    "res_df.set_index('cluster',inplace=True)\n",
    "ct_dic = res_df['cell type'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['Cell# raw'] = adata.obs['leiden']\n",
    "\n",
    "adata.obs['Cell# raw'].map(ct_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = init_subgraph()\n",
    "#draw_graph(subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_markers = []\n",
    "for string in cell_markers_df['cell_markers'].tolist():\n",
    "    exec(\"all_markers+=\"+string)\n",
    "hvgs = get_cluster_hvgs(adata)\n",
    "gene_list = list(set(all_markers+hvgs))\n",
    "\n",
    "mask = adata.obs['leiden'] == '1'\n",
    "exp_summary  = get_exp_summary(adata[mask], gene_list)\n",
    "\n",
    "cluster = '1'\n",
    "max_iter = 5\n",
    "exp_summary_dict ={'1': exp_summary}\n",
    "metadata_dict = {'1': 'human with colorectal cancer, sample from normal colorectal mucosa '}\n",
    "cell_markers_table = df2markdownTable(cell_markers_df)\n",
    "anno_strategy = 'Primary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "subgraph_res = subgraph.invoke(\n",
    "    input = {\n",
    "        #pars\n",
    "        \"anno_llm\": think_llm,\n",
    "        \"max_iter\" : 5,\n",
    "        #input\n",
    "        \"cluster\" : cluster,\n",
    "        \"anno_strategy\" : \"secondary\",\n",
    "        \"cell_markers_table\" : cell_markers_table,\n",
    "        \"exp_summary_dict\": exp_summary_dict,\n",
    "        \"metadata_dict\": metadata_dict,\n",
    "        \"anno_critique\" :\"\",\n",
    "        \"n_iter\": 0\n",
    "    },\n",
    "    config = config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_res['anno_result']['functional group'] = str(subgraph_res['anno_result']['functional group'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [pd.DataFrame([subgraph_res['anno_result']]), pd.DataFrame([subgraph_res['anno_result']])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"AnnoResDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['Cell#'] = adata.obs['leiden']\n",
    "adata.obs['Cell#'] = adata.obs['Cell#'].replace(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color='Cell#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"AnnoResDF.csv\")\n",
    "test['cluster'] = test['cluster'].astype('str')\n",
    "test = test[['cluster','cell type']]\n",
    "test = test.set_index('cluster').to_dict()['cell type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Packaging annotator\n",
    "#\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "\n",
    "# The annotator is combinatied from a parent graph (for collect importmation and parse the result) and a subgraph (for annotation using those infromation).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#Define state for subgraph\n",
    "class SubGraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    A dictionary structure to hold the state of subgraph operations including configuration, input, internal processing, \n",
    "    and output fields for cell type annotation tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configuration Parameters\n",
    "    anno_llm: ChatOpenAI  # LLM (Language Model) configured for annotations. Used to generate or assist in creating annotations.\n",
    "    max_iter: int  # Maximum number of iterations allowed for annotation processes.\n",
    "\n",
    "    # Input Data\n",
    "    cluster: str  # Name of the cluster being processed.\n",
    "    anno_strategy: str  # Strategy used for annotation, options are 'primary' or 'secondary'.\n",
    "    cell_markers_table: str  # Information on cell types and their markers formatted as a markdown table.\n",
    "    exp_summary_dict: dict  # Expression summary of marker genes and highly variable genes (HVGs) for each cluster. Keys are cluster names, values are dictionaries containing expression tables for each gene.\n",
    "    metadata_dict: dict  # Useful metadata for annotation, formatted as a markdown table.\n",
    "\n",
    "    # Internal State During Processing\n",
    "    n_iter: int  # Current iteration number during the annotation process.\n",
    "    anno_response: str  # Response generated by the LLM for annotation purposes.\n",
    "    anno_celltype: str  # Determined cell type for each cluster after annotation.\n",
    "    anno_critique: str  # Critiques or feedback on the annotation process or results.\n",
    "    decision: str  # Decision made based on critiques, guiding further actions or finalizing annotations.\n",
    "\n",
    "    # Output Data\n",
    "    anno_result: dict  # Final annotation result for the given cluster, structured as required for downstream analysis or reporting.\n",
    "\n",
    "#define subgraph\n",
    "#================================\n",
    "#def nodes\n",
    "#--------------------------------\n",
    "def node_annotation(\n",
    "        state: SubGraphState\n",
    "        ):\n",
    "    #pass parameters\n",
    "    llm = state[\"anno_llm\"]\n",
    "    cluster = state[\"cluster\"]\n",
    "    strategy = state[\"anno_strategy\"]\n",
    "    exp_summary_dict = state[\"exp_summary_dict\"]\n",
    "    metadata_dict = state[\"metadata_dict\"]\n",
    "    cell_markers_table = state[\"cell_markers_table\"]\n",
    "    critique = state[\"anno_critique\"]\n",
    "    n_iter = state[\"n_iter\"]\n",
    "    #convert to markdown table\n",
    "    exp_summary_table = exp_summary_dict[cluster]\n",
    "    metadata_table = metadata_dict[cluster]\n",
    "    #convert critique\n",
    "    if len(critique) > 1:\n",
    "        critique = \"\\nYou and your coworkers are collaborating on multiple rounds of annotations and corrections, and your coworkers will be evaluating your previous annotations, if not the first round; consider their evaluations before you annotate:\\n\" + critique\n",
    "    #set up instructions for different strategies\n",
    "    if strategy.lower() == 'secondary':\n",
    "        instruction = \"Since the current annotation is aimed at subpopulations of specific cell types that are very case specific, you do not necessarily have to adhere to the given cell types and their markers. But please still respect the given hierarchy of reference cell types as much as possible.\"\n",
    "    else:\n",
    "        instruction = \"Since the current annotation is aimed at the whole population of cell types, you should adhere to the given cell types and their markers as much as possible.\"\n",
    "#prompting\n",
    "    annotation_prompt = \"\"\"\n",
    "You are a bioinformatics expert in the field of single-cell RNAseq.\n",
    "You are going to annotate the cell type of the following cluster, its expression status is:\n",
    "{exp_summary_table}\n",
    "\n",
    "The cluster is from the following sample:\n",
    "{metadata_table}\n",
    "\n",
    "You can using the following cell types and cell markers earlier provided by another expert for hint:\n",
    "{cell_markers_table}\n",
    "\n",
    "{instruction}\n",
    "{critique}\n",
    "\n",
    "In your answer, please first analyze the gene expression of this cluster and then annotate this cluster with your knowledge and the provided cell types and cell markers and give reasons, the reasons should include:\n",
    "    1. key genes of the target cell type; \n",
    "    2. positively expressed genes that support the annotation results; \n",
    "    3. negatively expressed genes that support the annotation results; \n",
    "    4. conflicting or potentially confusing genes; and \n",
    "    5. your overall conclusions. \n",
    "\n",
    "Note that You don't have to follow the referenced markers for annotations, and you can take a certain amount of liberties when you think there is a more appropriate naming convention for the current subcluster. But be sure to give the cluster an annotation and a good reason for it.\n",
    "\n",
    "Finally, transcribe the results of the annotation to the end of your answer, using following json array format:\n",
    "```json\n",
    "[\n",
    "    \"annotated cell type\", \n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "    #build chain\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\n",
    "            \"exp_summary_table\", \n",
    "            \"metadata_table\", \n",
    "            \"cell_markers_table\", \n",
    "            \"instruction\", \n",
    "            \"critique\"],\n",
    "        template=annotation_prompt\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    #call llm\n",
    "    print(f\"Annotating cluster {cluster}...\")\n",
    "    response = chain.invoke({\n",
    "        \"exp_summary_table\": exp_summary_table,\n",
    "        \"metadata_table\": metadata_table,\n",
    "        \"cell_markers_table\": cell_markers_table,\n",
    "        \"instruction\": instruction,\n",
    "        \"critique\": critique\n",
    "    })\n",
    "    #parse response\n",
    "    cell_type = parse_jsonfromcontent(response.content)\n",
    "    cell_type = cell_type[0]\n",
    "    #recod interation\n",
    "    n_iter += 1\n",
    "    return {\n",
    "        \"anno_response\": response.content,\n",
    "        \"anno_celltype\": cell_type,\n",
    "        \"n_iter\": n_iter,\n",
    "    }\n",
    "\n",
    "\n",
    "def node_critic(state: SubGraphState):\n",
    "    #pass parameters\n",
    "    llm = state[\"anno_llm\"]\n",
    "    cluster = state[\"cluster\"]\n",
    "    cell_type = state[\"anno_celltype\"]\n",
    "    draft_response_wreason = state[\"anno_response\"]\n",
    "    exp_summary_dict = state[\"exp_summary_dict\"]\n",
    "    metadata_dict = state[\"metadata_dict\"]\n",
    "    cell_markers_table = state[\"cell_markers_table\"]\n",
    "    #convert to markdown table \n",
    "    exp_summary_table = exp_summary_dict[cluster]\n",
    "    metadata_table = metadata_dict[cluster]\n",
    "    #prompting\n",
    "    annotation_critic_prompt = \"\"\"\n",
    "You are a bioinformatics expert in the field of single-cell RNAseq.\n",
    "One of your coworkers has annotated this cluster as {cell_type} and given the results, you need to help him check the results and give your comments and reasons.\n",
    "The expression of this cluster is as follows:\n",
    "{exp_summary_table}\n",
    "\n",
    "The cluster is from the following sample:\n",
    "{metadata_table}\n",
    "\n",
    "The reason for your colleague's annotation is as follows:\n",
    "{draft_response_wreason}\n",
    "\n",
    "The list of referenced markers is as follows:\n",
    "{cell_markers_table}\n",
    "\n",
    "Give your evaluation and reasons for your colleague's annotation results. Then, append final decision to the end of your answer in the following json array format:\n",
    "```json\n",
    "{{\n",
    "    \"final decision\": str //  Chose from `Approved` if you think the given annotation result of is reasonable, otherwise add `Disapproved`\n",
    "}}\n",
    "\"\"\"\n",
    "    #build chain\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\n",
    "            \"cell_type\", \n",
    "            \"exp_summary_table\", \n",
    "            \"metadata_table\", \n",
    "            \"draft_response_wreason\", \n",
    "            \"cell_markers_table\"],\n",
    "        template=annotation_critic_prompt\n",
    "    )\n",
    "    chain = prompt | llm \n",
    "    #call llm\n",
    "    print(f\"Checking annotation for cluster {cluster}...\")\n",
    "    response = chain.invoke({\n",
    "        \"cell_type\": cell_type,\n",
    "        \"exp_summary_table\": exp_summary_table,\n",
    "        \"metadata_table\": metadata_table,\n",
    "        \"draft_response_wreason\": draft_response_wreason,\n",
    "        \"cell_markers_table\": cell_markers_table\n",
    "    })\n",
    "    #parse response\n",
    "    decision_dic = parse_jsonfromcontent(response.content)\n",
    "    decision = decision_dic[\"final decision\"]\n",
    "    return {\n",
    "        \"anno_critique\": response.content,\n",
    "        \"critic_decision\": decision,\n",
    "    }\n",
    "\n",
    "def node_finalize(state: SubGraphState):\n",
    "\n",
    "    cluster = state[\"cluster\"]\n",
    "    cell_type = state[\"anno_celltype\"]\n",
    "    anno_response = state[\"anno_response\"]\n",
    "    functional_anno = \"not applied\"\n",
    "    finnal_result = {\n",
    "        \"cluster\": cluster,\n",
    "        \"cell type\": cell_type,\n",
    "        \"functional group\": functional_anno,\n",
    "        \"reason\": anno_response,\n",
    "    }\n",
    "    print(\"Final annotation of\",cluster,\"is\",cell_type)\n",
    "    return {\n",
    "        \"anno_result\": finnal_result,\n",
    "    }\n",
    "\n",
    "def node_funcional_characterization(state: SubGraphState):\n",
    "    #pass parameters\n",
    "    llm = state[\"anno_llm\"]\n",
    "    cluster = state[\"cluster\"]\n",
    "    exp_summary_dict = state[\"exp_summary_dict\"]\n",
    "    metadata_dict = state[\"metadata_dict\"]\n",
    "    cell_type = state[\"anno_celltype\"]\n",
    "    anno_result = state[\"anno_result\"]\n",
    "    #convert to markdown table\n",
    "    exp_summary_table = exp_summary_dict[cluster]\n",
    "    metadata_table = metadata_dict[cluster]\n",
    "    #prompting\n",
    "    functional_prompt = \"\"\"\n",
    "You are a bioinformatics expert specializing in functional characterization of single-cell RNAseq subpopulations.\n",
    "You are tasked with performing functional profiling of the following subcluster, which has been preliminarily annotated as {cell_type}.\n",
    "\n",
    "Its detailed expression profile is:\n",
    "{exp_summary_table}\n",
    "\n",
    "The metadata of the current cluster are as follows, and inferences about functions and features can be made based on this meta information:\n",
    "{metadata_table}\n",
    "\n",
    "In your analysis, you should:\n",
    "1. Identify hallmark biological processes (e.g., stemness, apoptosis, cytokine production) \n",
    "2. Detect cellular state indicators (e.g., proliferative, quiescent, activated)\n",
    "3. Recognize specialized functional programs (e.g., metabolic activity, stress response)\n",
    "\n",
    "Your annotation rationale must explicitly address:\n",
    "1. Core functional markers driving the characterization\n",
    "2. Supportive co-expressed genes reinforcing the functional state\n",
    "3. Exclusion markers ruling out alternative functional states\n",
    "4. Ambiguous/conflicting expression patterns requiring interpretation\n",
    "5. Integration of evidence for final functional designation\n",
    "\n",
    "Annotation guidelines:\n",
    "- Combine known conventions with novel descriptors when justified (e.g., \"Senescent_epithelial\", \"IFNγ-high_CD8+_T\")\n",
    "- Consider gradient states using modifiers like \"progenitor\", \"transitioning\", or \"activated\"\n",
    "- Maintain biological plausibility while allowing subpopulation-specific terminology\n",
    "\n",
    "Present your analysis in this structure:\n",
    "1. **Functional Process Identification**\n",
    "- Highlight key pathways (e.g., \"Wnt signaling activation\")\n",
    "- Note cell cycle status indicators (e.g., G2/M phase genes)\n",
    "\n",
    "2. **State Characterization**\n",
    "- Identify stress/differentiation signatures\n",
    "- Detect secretory/effector programs\n",
    "\n",
    "3. **Consistency Assessment**\n",
    "- Verify alignment with parent cell type biology\n",
    "- Resolve expression conflicts\n",
    "\n",
    "Conclude with functional annotation append to your reason(note: you don't need to label the cell type), in this JSON format:\n",
    "```json\n",
    "[\n",
    "    \"functional_annotation\", \n",
    "]\n",
    "\"\"\"\n",
    "    #build chain\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\n",
    "            \"cell_type\", \n",
    "            \"exp_summary_table\", \n",
    "            \"metadata_table\"],\n",
    "        template=functional_prompt\n",
    "    )\n",
    "    chain = prompt | llm | JsonOutputParser()\n",
    "    #call llm\n",
    "    print(f\"Functional characterization for cluster {cluster}...\")\n",
    "    response = chain.invoke({\n",
    "        \"cell_type\": cell_type,\n",
    "        \"exp_summary_table\": exp_summary_table,\n",
    "        \"metadata_table\": metadata_table,\n",
    "    })\n",
    "    #parse response\n",
    "    functional_anno = response\n",
    "    anno_result[\"functional group\"] = functional_anno\n",
    "    return {\n",
    "        \"anno_result\": anno_result,\n",
    "    }\n",
    "\n",
    "\n",
    "#def decision functions\n",
    "#--------------------------------\n",
    "def decfun_decision(state: SubGraphState):\n",
    "    n_iter = state[\"n_iter\"]\n",
    "    cluster = state[\"cluster\"]\n",
    "    max_iter = state[\"max_iter\"]\n",
    "    decision = state[\"critic_decision\"]\n",
    "    if n_iter >= max_iter:\n",
    "        print(f\"Maximum number of annotation iterations reached for cluster {cluster}.\")\n",
    "        return \"finalize\"\n",
    "    else:\n",
    "        if decision.lower() == \"approved\":\n",
    "            print(f\"Annotation result for cluster {cluster} is satisfied.\")\n",
    "            return \"finalize\"\n",
    "        else:\n",
    "            print(f\"Annotation result for cluster {cluster} is not yed satisfied, for round\",n_iter)\n",
    "            return \"reflex\"\n",
    "\n",
    "def decfun_strategy(state: SubGraphState):\n",
    "    strategy = state[\"anno_strategy\"]\n",
    "    if strategy.lower() == \"secondary\":\n",
    "        return \"functional\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "#Build subgraph \n",
    "#--------------------------------\n",
    "subgraph_builder = StateGraph(SubGraphState)\n",
    "#nodes\n",
    "subgraph_builder.add_node(\"annotation\", node_annotation)\n",
    "subgraph_builder.add_node(\"critic\", node_critic)\n",
    "subgraph_builder.add_node(\"finalize\", node_finalize)\n",
    "subgraph_builder.add_node(\"functional\", node_funcional_characterization)\n",
    "#edges\n",
    "subgraph_builder.add_edge(START, \"annotation\")\n",
    "subgraph_builder.add_edge(\"annotation\", \"critic\")\n",
    "subgraph_builder.add_conditional_edges(\n",
    "    \"critic\", \n",
    "    decfun_decision,\n",
    "    {\n",
    "        \"finalize\":\"finalize\",\n",
    "        \"reflex\":\"annotation\"\n",
    "    }\n",
    "    )\n",
    "subgraph_builder.add_conditional_edges(\n",
    "    \"finalize\",\n",
    "    decfun_strategy,\n",
    "    {\n",
    "        \"functional\":\"functional\",\n",
    "        \"end\":END\n",
    "    }\n",
    "    )\n",
    "subgraph_builder.add_edge(\"functional\", END)\n",
    "#compile\n",
    "subgraph = subgraph_builder.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "#map-reduce with subraph test\n",
    "class mainstate(TypedDict):\n",
    "    A: str #pass not change\n",
    "    B: str\n",
    "    C: list #list of Es\n",
    "    D: Annotated[list, operator.add]\n",
    "\n",
    "class mapstate(TypedDict):\n",
    "    A: str #pass not change\n",
    "    B: str\n",
    "    c: str #list of Es\n",
    "\n",
    "\n",
    "class substate(TypedDict):\n",
    "    A: str \n",
    "    E: str #element of C\n",
    "\n",
    "\n",
    "def subnode_1(state: substate) -> substate:\n",
    "    print(state[\"A\"])\n",
    "    D = state[\"E\"] + \"_reduced_from_sub\"\n",
    "    return {\n",
    "        \"D\":[D]\n",
    "    }\n",
    "\n",
    "subbuilder = StateGraph(substate)\n",
    "subbuilder.add_node(\"subnode_1\",subnode_1)\n",
    "subbuilder.add_edge(START, \"subnode_1\")\n",
    "subbuilder.add_edge(\"subnode_1\",END)\n",
    "\n",
    "subgraph = subbuilder.compile()\n",
    "\n",
    "def mainnode_1(state: mainstate) -> mainstate:\n",
    "    print(\n",
    "        \"A\",state[\"A\"],\n",
    "        \"\\nB\",state[\"B\"],\n",
    "        \"\\nC\",state[\"C\"],\n",
    "        )\n",
    "    \n",
    "    return {}\n",
    "\n",
    "def call_subgraph(state: mapstate) -> mainstate:\n",
    "    subgraph_input = {\n",
    "        \"A\": state[\"A\"],\n",
    "        \"E\": state[\"c\"],\n",
    "    }\n",
    "    res = subgraph.invoke(subgraph_input)\n",
    "    return {\"D\":[res]}\n",
    "\n",
    "def mainnode_2(state: mainstate) -> mainstate:\n",
    "    print(state[\"D\"])\n",
    "    return {}\n",
    "\n",
    "\n",
    "def map_function(state: mainstate):\n",
    "    return [\n",
    "        Send(\"subgraph\", {\"A\":state[\"A\"],\"c\":c}) for c in state[\"C\"]\n",
    "    ]\n",
    "\n",
    "builder = StateGraph(mainstate)\n",
    "builder.add_node(\"node1\",mainnode_1)\n",
    "builder.add_node(\"subgraph\",call_subgraph)\n",
    "builder.add_node(\"node2\",mainnode_2)\n",
    "\n",
    "builder.add_edge(START, \"node1\")\n",
    "builder.add_conditional_edges(\n",
    "    \"node1\",\n",
    "    map_function,\n",
    "    [\n",
    "        \"subgraph\",\n",
    "    ]\n",
    ")\n",
    "builder.add_edge(\"subgraph\", \"node2\")\n",
    "builder.add_edge(\"node2\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({'A':'A','B':'B','C':['1','2','3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langgraph.types import Send\n",
    "#Define state for parent-graph\n",
    "class MainGraphState(TypedDict):\n",
    "    #parameters\n",
    "    max_iter: int #max iteration for annotation\n",
    "    anno_llm: ChatOpenAI #LLM for annotation, models with reasoning ability is recommended\n",
    "\n",
    "    #input\n",
    "    input_adata: ad.AnnData \n",
    "    cluster_key: str #clusters for annotation, e.g. 'leiden'\n",
    "    maker_df_dir: str #local direction of cell marker df\n",
    "    marker_offered: bool #if marker df offered and successfully load\n",
    "\n",
    "    #internal\n",
    "    metadata_summary: str #summary of input anndata\n",
    "    #metadata_col: list # list of metadata related columns from anndata\n",
    "    metadata_dict: dict #dictionary for metadata, where key is each cluster name and metadata for each cluster as item\n",
    "\n",
    "    target_cell_types: list #target cell types to annotate\n",
    "    anno_strategy: str #strategy for annotation, 'primary' or 'secondary' \n",
    "    cell_markers_table: str #markdown table for cell types and their markers\n",
    "    clusters: list #list of clusters in cluster_key, use for map\n",
    "    exp_summary_dic: dict #expression summary of marker genes and hvgs for each cluster, where cluster name as key and expression table for each genes as item\n",
    "    anno_results: Annotated[list[dict], operator.add] #annotation result for each cluster from subgraph\n",
    "    #output\n",
    "    anno_result_df: pd.DataFrame #annotation result for each cluster, where [cluster name], [annotated cell type], [reason], [functional group] as columns\n",
    "    output_adata: ad.AnnData #output anndata with cell type annotation\n",
    "\n",
    "\n",
    "class MapGraphState(TypedDict):\n",
    "    #parameters\n",
    "    anno_llm: ChatOpenAI #pass not chage\n",
    "    max_iter: int #pass not chage\n",
    "    #input\n",
    "    cluster: str #mapped from clusters from MainGraphState\n",
    "    anno_strategy: str #pass not chage\n",
    "    cell_markers_table: str #pass not chage\n",
    "    exp_summary_dic: dict #pass not chage\n",
    "    metadata_dict: dict #pass not chage\n",
    "\n",
    "def node_get_metadata(state:MainGraphState):\n",
    "    \"\"\"\n",
    "    Extract useful metadata columns from an AnnData object for cell type annotation using a language model (LLM).\n",
    "    \n",
    "    This function:\n",
    "    1. Generates a summary of the AnnData object.\n",
    "    2. Uses an LLM to select metadata columns relevant to cell type annotation.\n",
    "    3. Summarizes the selected metadata for the entire dataset and per cluster.\n",
    "    \n",
    "    Parameters:\n",
    "    - adata (AnnData): AnnData object containing single-cell RNA sequencing data.\n",
    "    - llm: Language model instance used to select metadata columns.\n",
    "    - group (str): Column name in adata.obs for clustering (default: 'leiden').\n",
    "    \n",
    "    Returns:\n",
    "    - useful_meta_cols (list): List of metadata column names selected by the LLM.\n",
    "    - metadata_summary (str): Summary of selected metadata columns for the entire dataset.\n",
    "    - metadata_dict (dict): Summaries of selected metadata columns for each cluster.\n",
    "    \n",
    "    \"\"\"\n",
    "    #--------------------------------\n",
    "    #pass parameters\n",
    "    llm = state[\"anno_llm\"]\n",
    "    group = state[\"cluster_key\"]\n",
    "    adata = state[\"input_adata\"]\n",
    "\n",
    "    #--------------------------------\n",
    "    #data presception, step1, get over all presception\n",
    "    print(\"Getting summary of given data...\")\n",
    "    data_type, adata_summary = data_perception(adata)\n",
    "    print(\"given data is\",data_type)\n",
    "    #--------------------------------\n",
    "    #call for llm\n",
    "    chose_column_prompt = \"\"\"\n",
    "    You are a biologist who is familiar with the metadata of the dataset.\n",
    "    You are given a anndata with the following summary:\n",
    "    {adata_summary}\n",
    "    Please choose the metadata column that you think is most useful for cell type annotatation in adata.obs, for example we need to know the sample species, tissue and diease for correct annotation. And if there is pre-annotated cell type(s), also return the column name for future use.\n",
    "\n",
    "    Please return all columns that are useful for cell type annotation in following json array format:\n",
    "    ```json\n",
    "    [\n",
    "        \"column1\", \n",
    "        \"column2\", \n",
    "        ...\n",
    "    ]\n",
    "    ```\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = [\"adata_summary\"],\n",
    "        template = chose_column_prompt,\n",
    "    )\n",
    "    chain =  prompt | llm | JsonOutputParser()\n",
    "    i = 0 \n",
    "    while i<3:\n",
    "        try:\n",
    "            meta_cols =  chain.invoke({\"adata_summary\": adata_summary})\n",
    "            break\n",
    "        except:\n",
    "            i+=1\n",
    "\n",
    "    #--------------------------------\n",
    "    #data presception, step2, get detailed presception of each column, for whole data and each cluster\n",
    "    print(\"Collecting data metadata summary...\")\n",
    "    metadata_summary =  get_dfcol_summaries(adata.obs, meta_cols)\n",
    "    metadata_dict = {}\n",
    "    for cluster in adata.obs[group].unique():\n",
    "        metadata_dict[cluster] = get_dfcol_summaries(adata[adata.obs[group] == cluster].obs, meta_cols)\n",
    "\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"metadata_summary\": metadata_summary,\n",
    "        \"metadata_dict\": metadata_dict,\n",
    "    }\n",
    "\n",
    "def node_get_target_celltypes(state:MainGraphState):\n",
    "    #--------------------------------\n",
    "    #pass parameters\n",
    "    llm = state[\"anno_llm\"]\n",
    "    metadata_summary = state[\"metadata_summary\"]\n",
    "    df_dir = state[\"maker_df_dir\"]\n",
    "    #--------------------------------\n",
    "    #call for llm\n",
    "    chose_celltype_prompt = \"\"\"\n",
    "    As a biologist familiar with the annotation of single-cell RNA-seq data, you will handle an anndata object containing specific metadata. \n",
    "    Your task is to select the most suitable target cells for cell type annotation based on the provided sample metadata, considering factors such as disease status, sample tissue origin, and species information.\n",
    "\n",
    "    The metadata summary from given anndata.obs:\n",
    "    {metadata_summary}\n",
    "\n",
    "    ### Task Steps\n",
    "\n",
    "    1. **Understand Sample Background**:\n",
    "    - Analyze the provided `metadata` to understand whether the samples involve healthy controls versus disease states, if there are any drug interventions, etc. These factors are crucial for formulating an annotation strategy.\n",
    "\n",
    "    2. **Determine Annotation Strategy**:\n",
    "    - **Primary Cell Type Annotation**: Based on the sample type (e.g., PBMC samples typically include immune cells), choose the most relevant cell types as primary annotation targets. This strategy is generally used for samples with higher specificity, such as human and animal organ samples.\n",
    "    - **Secondary Cell Type or Functional Annotation**: On top of the primary cell types, consider further subdividing cell types (e.g., distinguishing CD4+ T cells from CD8+ T cells within T cells). However, avoid having both parent and child cell types at the same resolution level to prevent classification confusion. This strategy is generally used for samples with relatively low specificity, such as cell subtypes of major cell types that are already annotated, cell lines cultured in vitro, and so on.\n",
    "\n",
    "    3. **Select Appropriate Annotation Targets**:\n",
    "    - Based on the purpose of biological differential analysis, precisely identify the cell types that need annotation to support subsequent marker identification. Ensure that the names of the annotated cell types are common and easily recognizable.\n",
    "\n",
    "    ### Important Notes\n",
    "    - In your response, first list the primary cell types suitable for the current dataset as annotation targets.\n",
    "    - Then, re-normalize these targets according to the hierarchical levels of cell types. For example, if annotations are already made at the level of T cells and B cells, try not to subdivide into CD4+ T cells and CD8+ T cells; Th2 and Treg should never appear at the same resolution level as T cells and B cells. Ensure that cell types and their subsets do not appear together in the annotation results to avoid ambiguous categorization.\n",
    "\n",
    "    By following this approach, you can effectively provide precise cell type annotation recommendations for single-cell RNA-seq data analysis.\n",
    "\n",
    "    Please return as many as possible cell types that are suitable targets for annotations, in the following json format:\n",
    "    ```json\n",
    "    {{\n",
    "        \"annotation strategy\": str // Chose from `primary` which indicate major cell type annotations, or `secondary` for cell subpopulation and/or functional group annotations.\n",
    "        \"cell_types\": list // major cell type or cell subpopulation names, e.g. [\"cell type 1\", \"cell type 2\", ...].\n",
    "    }}\n",
    "    \n",
    "    ```\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = [\"metadata_summary\"],\n",
    "        template = chose_celltype_prompt,\n",
    "    )\n",
    "    chain =  prompt | llm | JsonOutputParser()\n",
    "    i = 0\n",
    "    print(\"Looking for target cell types for annotation...\")\n",
    "    while i < 3:\n",
    "        try:\n",
    "            response =  chain.invoke({\"metadata_summary\": metadata_summary})\n",
    "            #--------------------------------\n",
    "            #parse parameters\n",
    "            strategy = response[\"annotation strategy\"]\n",
    "            cell_types = response[\"cell_types\"]\n",
    "            break\n",
    "        except:\n",
    "            i+=1\n",
    "    cell_types_str = \"Recommended annotation target cell types are:\\n\"\n",
    "    for cell in cell_types:\n",
    "        cell_types_str += cell + '\\n'\n",
    "    print(cell_types_str)\n",
    "\n",
    "    #--------------------------------\n",
    "    #trying to use provided cell markers\n",
    "    try:\n",
    "        marker_df = pd.read_csv(maker_df_dir)\n",
    "        print(\"Cell marker dataframe loaded.\")\n",
    "        try:\n",
    "            cell_markers_table = df2markdownTable(marker_df)\n",
    "            marker_offered = True\n",
    "        except:\n",
    "            print(\"Failed to convert cell marker dataframe to markdown.\")\n",
    "            marker_offered = False\n",
    "            cell_markers_table = \"\"\n",
    "    except:\n",
    "        marker_offered = False\n",
    "        cell_markers_table = \"\"\n",
    "\n",
    "    return {\n",
    "        \"anno_strategy\": strategy,\n",
    "        \"target_cell_types\": cell_types,\n",
    "        \"marker_offered\":marker_offered,\n",
    "        \"cell_markers_table\": cell_markers_table,\n",
    "    }\n",
    "\n",
    "def scrape_markers(\n",
    "        cell_type, \n",
    "        llm, \n",
    "        query,\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Scrape and retrieve marker genes for a given cell type using web search results and a language model (LLM).\n",
    "\n",
    "    This function:\n",
    "    1. Performs a web search based on the cell type and query.\n",
    "    2. Formats the search results into a readable string.\n",
    "    3. Uses a language model to recall and refine marker genes based on the search results.\n",
    "    4. Returns the LLM's full response and the extracted list of markers.\n",
    "\n",
    "    Parameters:\n",
    "    - llm: Language model instance used to process and refine the marker list.\n",
    "    - cell_type (str): The cell type for which marker genes are being retrieved (e.g., \"T-cell\").\n",
    "    - query (str): The search query to retrieve relevant web content (e.g., \"marker genes\").\n",
    "\n",
    "    Returns:\n",
    "    - response_content (str): The complete response from the LLM, including its thought process.\n",
    "    - markers (list): A list of marker genes extracted from the LLM's response in JSON format.\n",
    "    \"\"\"\n",
    "    #web scraping \n",
    "    print(f\"Trying to fetch cell markers for {cell_type} from web.\")\n",
    "    try:\n",
    "        web_res = web_retriever.invoke(cell_type + ' ' + query)\n",
    "        #parse search result\n",
    "        search_res = '============\\n'\n",
    "        for i, doc in enumerate(web_res, start=1):\n",
    "            search_res += f\"Web page {i}:\\n{doc.page_content}\\n\\n\"\n",
    "    except:\n",
    "        print(\"Web search failed\")\n",
    "        search_res = \"Web search failed, please use your own memory and knowledge about cell types and thire markers.\"\n",
    "    #process search result\n",
    "    get_markers = \"\"\"\n",
    "    You are a bioinformatics expert in the field of single-cell RNAseq.\n",
    "    Your task is to provide researchers with marker genes for {cell_type}. Follow these steps:\n",
    "    1. Recall the key marker genes for this cell type based on your knowledge.\n",
    "    2. Refine the list by adding or removing markers based on the web search results, providing reasons for each change.\n",
    "    3. Output your thought process and the final list of markers in the specified JSON format.\n",
    "\n",
    "    Web search results:\n",
    "    {search_results}\n",
    "    \n",
    "    Please output your thought process along with an organized cell types markers that are suitable targets for scRNAseq annotation, the markers in the following json array after your thought process:\n",
    "    ```json\n",
    "    [\n",
    "        \"marker1\", \n",
    "        \"marker2\", \n",
    "        ...\n",
    "    ]\n",
    "    ```\n",
    "    \"\"\"\n",
    "    #build chain\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = [\"cell_types\", \"search_results\"],\n",
    "        template = get_markers,\n",
    "    )\n",
    "    chain = prompt | llm \n",
    "    \n",
    "    #invoke llm\n",
    "    response =  chain.invoke(\n",
    "        {\n",
    "            \"cell_type\": cell_type,\n",
    "            \"search_results\": search_res,\n",
    "        })\n",
    "    #convert to python list\n",
    "    markers = parse_jsonfromcontent(response.content)\n",
    "    \n",
    "    return response.content, markers\n",
    "\n",
    "def node_scrape_markers(state: MainGraphState):\n",
    "    \"\"\"\n",
    "    Scrapes cell type markers based on provided metadata and cell types.\n",
    "    \n",
    "    This function uses a language model to generate a search query prefix from the metadata summary.\n",
    "    It then scrapes markers for each target cell type using this query in parallel.\n",
    "    The results are saved to a CSV file and returned as a markdown table.\n",
    "    \n",
    "    Parameters:\n",
    "    state (MainGraphStat): A state object containing necessary parameters.\n",
    "        - anno_llm: The language model for annotation.\n",
    "        - metadata_summary: Summary of metadata from collected data.\n",
    "        - target_cell_types: List of cell types to scrape markers for.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the markdown table of cell types and their markers.\n",
    "    \"\"\"\n",
    "    #--------------------------------\n",
    "    #parse parameters\n",
    "    llm = state[\"anno_llm\"]\n",
    "    metadata_summary = state[\"metadata_summary\"]\n",
    "    cell_types = state[\"target_cell_types\"]\n",
    "    print(\"Scraping cell markers...\")\n",
    "\n",
    "    #--------------------------------\n",
    "    #generate search query\n",
    "    search_query_prompt = \"\"\"\n",
    "    You are a bioinformatics expert in the field of single-cell RNAseq.\n",
    "    Based on the metadata of collected data below, generate a <20-word search prefix for cell type markers:\n",
    "    {metadata_summary}\n",
    "    \n",
    "    Note:\n",
    "    1. You just need to organize the species, sampling tissue, etc. as a prefix and I'll add the specific cell type before your search query, example: \"[cell type] markers for human in breast, breast cancer\",\n",
    "    2. Provide only the search query, without any intermediate thought process.\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = [\"metadata_summary\"],\n",
    "        template = search_query_prompt,\n",
    "    )\n",
    "    query_chain = prompt | llm | StrOutputParser()\n",
    "    query = query_chain.invoke({\"metadata_summary\": metadata_summary})\n",
    "\n",
    "    #--------------------------------\n",
    "    #scape cell markers in parallel\n",
    "    process_marker_scrape = partial(\n",
    "        scrape_markers,\n",
    "        llm = llm, \n",
    "        query = query,\n",
    "        )\n",
    "    \n",
    "    all_dfs = []\n",
    "    errors = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_marker_scrape, cell_type):cell_type for cell_type in cell_types}\n",
    "        for future in as_completed(futures):\n",
    "            cell_type = futures[future]\n",
    "            try:\n",
    "                reason, markers = future.result()\n",
    "                df = pd.DataFrame([{\n",
    "                    \"cell_type\": cell_type,\n",
    "                    \"markers\": markers,\n",
    "                    \"reason\": reason,\n",
    "                }])\n",
    "                all_dfs.append(df)\n",
    "            except Exception as exc:\n",
    "                errors.append((cell_type, exc))\n",
    "                #print(f'{cell_type} generated an exception: {exc}')\n",
    "    # print errors if there are any\n",
    "    if errors:\n",
    "        print(\"The following cell types had errors during scraping:\")\n",
    "        for cell_type, exc in errors:\n",
    "            print(f\"{cell_type}: {exc}\")\n",
    "\n",
    "    #--------------------------------\n",
    "    #parse result and save to csv\n",
    "    cell_markers_df = pd.concat(all_dfs,ignore_index=True)\n",
    "    cell_markers_df.to_csv(\"scraped_cell_markers.csv\", encoding=\"utf-8-sig\", index=False)\n",
    "    print(\"Cell type and marker list saved to csv.\")\n",
    "    cell_markers_table = df2markdownTable(cell_markers_df[['cell_type','markers']])\n",
    "    return {\n",
    "        \"cell_markers_table\":cell_markers_table,\n",
    "    }\n",
    "\n",
    "def node_get_expresssummary(state: MainGraphState):\n",
    "    \"\"\"\n",
    "    Generates expression summaries for clusters in a single-cell RNAseq dataset.\n",
    "    \n",
    "    This function processes the AnnData object to extract marker genes and highly variable genes (HVGs)\n",
    "    for each cluster. It then computes expression summaries for these genes in each cluster.\n",
    "    \n",
    "    Parameters:\n",
    "    state (MainGraphStat): A state object containing necessary parameters.\n",
    "        - input_adata: AnnData object containing the single-cell RNAseq data.\n",
    "        - cluster_key: The key in adata.obs that defines the cluster assignments.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing:\n",
    "        - clusters: List of unique cluster identifiers.\n",
    "        - exp_summary_dict: A dictionary with clusters as keys and their expression summaries as values.\n",
    "    \"\"\"\n",
    "    import ast\n",
    "    import scanpy as sc\n",
    "    #--------------------------------\n",
    "    #parse parameters\n",
    "    adata = state[\"input_adata\"]\n",
    "    group = state[\"cluster_key\"]\n",
    "    clusters = adata.obs[group].unique().tolist()\n",
    "    print(\"Getting data gene expressing summary...\")\n",
    "\n",
    "    #--------------------------------\n",
    "    #get cell markers \n",
    "    cell_markers_df = pd.read_csv(\"scraped_cell_markers.csv\")\n",
    "    marker_genes = []\n",
    "    for _, row in cell_markers_df.iterrows():\n",
    "        if type(row['markers']) == list:\n",
    "            marker_genes += row['markers']\n",
    "        elif type(row['markers']) == str:\n",
    "            marker_genes += ast.literal_eval(row['markers'])\n",
    "\n",
    "    #--------------------------------\n",
    "    #get hvgs for each cluster\n",
    "    if 'rank_genes_groups' not in adata.uns:\n",
    "        sc.tl.rank_genes_groups(adata, groupby=group)\n",
    "    hvgs = []\n",
    "    for clst in clusters:\n",
    "        hvgs += list(adata.uns['rank_genes_groups']['names'][clst][:5])\n",
    "    gene_list = list(set(marker_genes + hvgs))\n",
    "\n",
    "    #--------------------------------\n",
    "    #get expression summary\n",
    "    exp_summary_dict = {}\n",
    "    for clst in clusters:\n",
    "        mask = adata.obs[group] == clst\n",
    "        exp_sum = get_exp_summary(adata[mask],gene_list)\n",
    "        exp_summary_dict[clst] = exp_sum\n",
    "\n",
    "    return {\n",
    "        \"clusters\":clusters,\n",
    "        \"exp_summary_dict\":exp_summary_dict,\n",
    "    }\n",
    "    \n",
    "def node_annotation_mapped(state: MapGraphState):\n",
    "    subgraph_input = {\n",
    "        #pars\n",
    "        \"anno_llm\": state[\"anno_llm\"],\n",
    "        \"max_iter\" : state[\"max_iter\"],\n",
    "        #input\n",
    "        \"cluster\" : state[\"cluster\"],\n",
    "        \"anno_strategy\" : state[\"anno_strategy\"],\n",
    "        \"cell_markers_table\" : state[\"cell_markers_table\"],\n",
    "        \"exp_summary_dict\": state[\"exp_summary_dict\"],\n",
    "        \"metadata_dict\": state[\"metadata_dict\"],\n",
    "        #sub graph only\n",
    "        \"anno_critique\" :\"\",\n",
    "        \"n_iter\":0\n",
    "    }\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    print(\"Calling subgraph for annotation...\")\n",
    "    #call subgraph\n",
    "    subgraph_res = subgraph.invoke(subgraph_input, config=config)\n",
    "\n",
    "    return {\"anno_results\":[subgraph_res['anno_result']]}\n",
    "    \n",
    "\n",
    "\n",
    "def node_normalize_celltype(state: MainGraphState):\n",
    "    #pass parameters\n",
    "    llm = state[\"anno_llm\"]\n",
    "    metadata_summary = state[\"metadata_summary\"]\n",
    "    anno_results = state[\"anno_results\"]\n",
    "    adata = state[\"input_adata\"]\n",
    "    print(\"Normalizing major cell type annotations...\")\n",
    "    #convert annotation result to dataframe\n",
    "    res_df_list = []\n",
    "    for res_dic in anno_results:\n",
    "        df_temp = pd.DataFrame([res_dic])\n",
    "        res_df_list.append(df_temp)\n",
    "    anno_results_df = pd.concat(res_df_list,ignore_index=True)\n",
    "    anno_results_df.to_csv('AnnoResDF.csv')\n",
    "    print('Raw annotation result saved as csv.')\n",
    "    #get unique cell types\n",
    "    annotated_cell_types = anno_results_df[\"cell type\"].unique().tolist()\n",
    "    #call llm\n",
    "    normaliztion_prompt = \"\"\"\n",
    "    As a biology researcher specializing in diverse cell types, you have been entrusted with the task of refining cell type annotations derived from scRNA-seq data processed by a colleague. The current annotations exhibit variability in granularity and require standardization to ensure uniformity across the dataset.\n",
    "\n",
    "    Your objective is to normalize these annotations by leveraging the provided sample metadata and the comprehensive list of cell types identified. This process involves several key steps:\n",
    "        1.Purification of Annotations: Begin by eliminating any extraneous or irrelevant information present within the annotation results to streamline the dataset.\n",
    "        2.Hierarchical Grouping: Consolidate subtypes under their corresponding parent cell types to achieve a coherent hierarchical structure. This step ensures that all annotations are represented at a consistent level of detail. e.g. \"CD4+ memory T cells\" should be consolidated under \"CD4+ T cells\" to  \"CD8+ T cells\" \n",
    "        3.Standardization of Nomenclature: Apply appropriate capitalization rules to each cell type designation for clarity and professionalism. Proper formatting not only enhances readability but also aligns with scientific conventions.\n",
    "    By meticulously executing these steps, you will produce a refined and standardized set of cell type annotations that maintain consistency throughout the entire dataset.\n",
    "\n",
    "    **Inputs:**\n",
    "    - Sample Metadata: \n",
    "    `{metadata_summary}`\n",
    "\n",
    "    - Cell Types:\n",
    "    `{annotated_cell_types}`\n",
    "\n",
    "    **Output Requirement:**\n",
    "    Please provide the normalized cell types in JSON format as follows:\n",
    "    ```json\n",
    "    {{\n",
    "        \"old_cell_type_name_1\": str,\\\\ \"normalized_cell_type_name_1\"\n",
    "        \"old_cell_type_name_2\": str, \\\\\"normalized_cell_type_name_2\",\n",
    "        ...\n",
    "    }}\n",
    "    ```\n",
    "    Ensure each key-value pair accurately reflects the mapping from the original to the normalized cell type names, facilitating easier comparison and analysis of the scRNA-seq data.\n",
    "    \"\"\"\n",
    "    #build chain\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"metadata_summary\", \"annotated_cell_types\"],\n",
    "        template=normaliztion_prompt\n",
    "    )\n",
    "    i = 0\n",
    "    while i < 3:\n",
    "        try:\n",
    "            chain = prompt | llm | JsonOutputParser()\n",
    "            response = chain.invoke({\n",
    "                \"metadata_summary\": metadata_summary,\n",
    "                \"annotated_cell_types\": annotated_cell_types\n",
    "            })\n",
    "            #get back to dataframe\n",
    "            anno_results_df['norm. cell type'] = anno_results_df[\"cell type\"]\n",
    "            anno_results_df['norm. cell type'].replace(response, inplace=True)\n",
    "            break\n",
    "        except:\n",
    "            i+=1\n",
    "    #save to csv \n",
    "    anno_results_df.to_csv('AnnoResDF.csv')\n",
    "    print('Normalized annotation result saved as csv.')\n",
    "    anno_dic = anno_results_df[['cluster','cell type']].to_dict()\n",
    "    #get back to adata\n",
    "    adata.obs[\"cell#\"] = adata.obs[\"leiden\"]\n",
    "    adata.obs[\"cell#\"] = adata.obs[\"cell#\"].replace(anno_dic)\n",
    "    return {\n",
    "        \"anno_result_df\": anno_results_df,\n",
    "        \"output_adata\": adata,\n",
    "    }\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "#Define decision functions for subgraph\n",
    "def decision_scrapemarkers(state:MainGraphState):\n",
    "    marker_offered = state[\"marker_offered\"]\n",
    "    if marker_offered:\n",
    "        return \"scrape markers\"\n",
    "    else:\n",
    "        return \"skip scrape\"\n",
    "    \n",
    "#----------------------------------------------------------------\n",
    "#Define map-reduce functions for subgraph\n",
    "def map_annotation(state:MainGraphState):\n",
    "    #return a list of `Send` objects, each `Send` object consists of the name of a node in the graph\n",
    "    return [Send(\"annotation_subgraph\", {\n",
    "        \"anno_llm\": state[\"anno_llm\"],\n",
    "        \"max_iter\": state[\"max_iter\"],\n",
    "        \"anno_strategy\": state[\"anno_strategy\"],\n",
    "        \"cell_markers_table\": state[\"cell_markers_table\"],\n",
    "        \"exp_summary_dict\": state[\"exp_summary_dict\"],\n",
    "        \"metadata_dict\": state[\"metadata_dict\"],\n",
    "        \"cluster\":s,\n",
    "        }) for s in state[\"clusters\"]]\n",
    "\n",
    "max_retry = 3\n",
    "#Build subgraph \n",
    "maingraph_builder = StateGraph(MainGraphState)\n",
    "#nodes\n",
    "maingraph_builder.add_node(\"get_metadata\", node_get_metadata, retry=RetryPolicy(max_attempts=max_retry))\n",
    "maingraph_builder.add_node(\"get_targetcell\", node_get_target_celltypes, retry=RetryPolicy(max_attempts=max_retry))\n",
    "maingraph_builder.add_node(\"scrape_markers\", node_scrape_markers, retry=RetryPolicy(max_attempts=max_retry))\n",
    "maingraph_builder.add_node(\"get_expression\", node_get_expresssummary, retry=RetryPolicy(max_attempts=max_retry))\n",
    "maingraph_builder.add_node(\"annotation_subgraph\", node_annotation_mapped, retry=RetryPolicy(max_attempts=max_retry))\n",
    "maingraph_builder.add_node(\"normalize_celltype\", node_normalize_celltype, retry=RetryPolicy(max_attempts=max_retry))\n",
    "#edges\n",
    "maingraph_builder.add_edge(START, \"get_metadata\")\n",
    "maingraph_builder.add_edge(\"get_metadata\", \"get_targetcell\")\n",
    "maingraph_builder.add_conditional_edges(\n",
    "    \"get_targetcell\",\n",
    "    decision_scrapemarkers,\n",
    "    {\n",
    "        \"scrape markers\":\"scrape_markers\",\n",
    "        \"skip scrape\":\"get_expression\",\n",
    "    }\n",
    ")\n",
    "maingraph_builder.add_edge(\"scrape_markers\", \"get_expression\")\n",
    "maingraph_builder.add_conditional_edges(\n",
    "    \"get_expression\",\n",
    "    map_annotation,\n",
    "    [\n",
    "        \"annotation_subgraph\",\n",
    "    ]\n",
    ")\n",
    "maingraph_builder.add_edge(\"annotation_subgraph\", \"normalize_celltype\")\n",
    "maingraph_builder.add_edge(\"normalize_celltype\", END)\n",
    "#compile\n",
    "maingraph = maingraph_builder.compile(\n",
    "    checkpointer=MemorySaver(), #useing standard sql memory saver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(maingraph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "res = maingraph.invoke(\n",
    "    input = {\n",
    "        #pars\n",
    "        \"anno_llm\": think_llm,\n",
    "        \"max_iter\" : 5,\n",
    "        #input\n",
    "        \"input_adata\": adata,\n",
    "        \"cluster_key\" : \"leiden\",\n",
    "        \"maker_df_dir\": \"\",\n",
    "    },\n",
    "    config = config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maingraph.get_state(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test maingraph\n",
    "\n",
    "meta_cols, meta_sum, meta_dic = node_get_metadata(adata=adata, llm=think_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_celltypes = node_get_target_celltypes(think_llm, meta_sum)\n",
    "target_celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = node_scrape_markers(think_llm, meta_sum)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason, markers = scrape_markers(think_llm,'Epithelial cells',query )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = node_scrape_markers(think_llm, meta_sum, target_celltypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mark_df = pd.concat(all_dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cell_mark_df['markers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mark_df.to_csv(\"scraped_cell_markers.csv\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_marker_df = pd.read_csv(\"scraped_cell_markers.csv\")\n",
    "cell_marker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers= []\n",
    "for _, row in cell_marker_df.iterrows():\n",
    "    if type(row['markers']) == list:\n",
    "        markers += row['markers']\n",
    "    elif type(row['markers']) == str:\n",
    "        markers += ast.literal_eval(row['markers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_markers_table = df2markdownTable(cell_mark_df[['cell_type','markers']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_sum_dic = node_get_expresssummary(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exp_sum_dic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIA-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
