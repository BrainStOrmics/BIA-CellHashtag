import pandas as pd
import numpy as np
import scanpy as sc
import pickle

from typing import TypedDict, Annotated, Optional
#from anndata._core.anndata import AnnData
import operator 
#langchain
from langchain_openai.chat_models.base import ChatOpenAI
from langchain.prompts import  PromptTemplate
from langchain_core.output_parsers import  JsonOutputParser, StrOutputParser
#langgraph
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.pregel import RetryPolicy
from langgraph.types import Send
#from langgraph.types import interrupt
#plot graph
from IPython.display import Image, display
#for parallel
from functools import partial
from concurrent.futures import ThreadPoolExecutor, as_completed
#import utils
from .utils import *
from ._prompts import *

#----------------------------------------------------------------
#Define state for subgraph
class SubGraphState(TypedDict):
    """
    A dictionary structure to hold the state of subgraph operations including configuration, input, internal processing, 
    and output fields for cell type annotation tasks.
    """
    # Configuration Parameters
    anno_llm: ChatOpenAI  # LLM (Language Model) configured for annotations. Used to generate or assist in creating annotations.
    max_iter: int # Maximum number of iterations allowed for annotation processes.

    # Input Data
    cluster: str  # Name of the cluster being processed.
    anno_strategy: str  # Strategy used for annotation, options are 'primary' or 'secondary'.
    cell_markers_table: str  # Information on cell types and their markers formatted as a markdown table.
    exp_summary_dict: dict  # Expression summary of marker genes and highly variable genes (HVGs) for each cluster. Keys are cluster names, values are dictionaries containing expression tables for each gene.
    metadata_dict: dict  # Useful metadata for annotation, formatted as a markdown table.

    # Internal State During Processing
    n_iter: int# Current iteration number during the annotation process.
    anno_response: str  # Response generated by the LLM for annotation purposes.
    anno_celltype: str  # Determined cell type for each cluster after annotation.
    anno_critique: str  # Critiques or feedback on the annotation process or results.
    decision: str  # Decision made based on critiques, guiding further actions or finalizing annotations.

    # Output Data
    anno_result: dict  # Final annotation result for the given cluster, structured as required for downstream analysis or reporting.

#----------------------------------------------------------------
#Define state for maingraph
class MainGraphState(TypedDict):
    #parameters
    max_iter: int #max iteration for annotation
    anno_llm: ChatOpenAI #LLM for annotation, models with reasoning ability is recommended

    #input
    adata_dir: str #pickle temp file dir for anndata  
    cluster_key: str #clusters for annotation, e.g. 'leiden'
    maker_df_dir: str #local direction of cell marker df
    marker_offered: bool #if marker df offered and successfully load

    #internal
    metadata_summary: str #summary of input anndata
    #metadata_col: list # list of metadata related columns from anndata
    metadata_dict: dict #dictionary for metadata, where key is each cluster name and metadata for each cluster as item

    target_cell_types: list #target cell types to annotate
    anno_strategy: str #strategy for annotation, 'primary' or 'secondary' 
    cell_markers_table: str #markdown table for cell types and their markers
    clusters: list #list of clusters in cluster_key, use for map
    exp_summary_dic: dict #expression summary of marker genes and hvgs for each cluster, where cluster name as key and expression table for each genes as item
    anno_results: Annotated[list[dict], operator.add] #annotation result for each cluster from subgraph
    #output


class MapGraphState(TypedDict):
    #parameters
    anno_llm: ChatOpenAI #pass not chage
    max_iter: int #pass not chage
    #input
    cluster: str #mapped from clusters from MainGraphState
    anno_strategy: str #pass not chage
    cell_markers_table: str #pass not chage
    exp_summary_dic: dict #pass not chage
    metadata_dict: dict #pass not chage

#----------------------------------------------------------------
#Define CellHastag Agent class
class CellHashtagAgent:
    """The CellHashtagAgent class is responsible for initializing and running the Cell# agent for cell type annotation of single-cell RNA sequencing data.
    It manages the initialization of the subgraph, main graph, and web scraper, and performs annotation tasks.
    """
    def __init__(
      self,
      web_scraper_api_key: Optional[str],
      web_scraper:str = 'Tavily',
        k_web_res: int = 7,
        max_retry: int = 3,
        ):
        """
        Initialize CellHashtagAgent
        Parameters.
        - web_scraper_api_key (Optional[str]): API key for web scraper. If None, web scraping may be skipped.
        - web_scraper (str): The web scraper to use, defaults to 'Tavily'.
        - k_web_res (int): number of web results per type, defaults to 7.
        - max_retry (int): the maximum number of retries for a node operation, defaults to 3.
        """
        try:
            self.web_scraper_api_key = web_scraper_api_key
        except:
            print("Web scraper api not provided, web search will not be available.")
            self.web_scraper_api_key = ""
        self.web_scraper = web_scraper
        self.k_web_res = k_web_res
        self.max_retry = max_retry
        self.subgraph = None
        self.maingraph = None
        self.web_retriever = None
        print("Initializing Cell# Agent")
        #set up web scraper
        try:
            self.web_retriever = self._set_web_scraper()
            print('Web scraper ready.')
        except Exception as e:
            print(f'Web scraper NOT setted: {e}')
        #set up subgraph
        try:
            self.subgraph = self._init_subgraph()
            print('Subgraph ready')
        except Exception as e:
            print(f'Failed to initialize subgraph with error: {e}')
            raise
        #try set up whole graph
        try:
            self.graph = self._init_graph()
            print("Cell# agent ready.")
        except Exception as e:
            print(f'Failed to initialize Cell# agent with error: {e}')
            raise

    def _set_web_scraper(self):
        """If web scraper API provided"""
        if self.web_scraper_api_key:
            return set_web_scraper(self.web_scraper_api_key, scraper=self.web_scraper, k_web_per_type=self.k_web_res)
        return None
    
    def _init_subgraph(self):
        """Initial subgraph, for annotation"""
        subgraph_builder = StateGraph(SubGraphState)
        #nodes
        subgraph_builder.add_node(
            "annotation", 
            self._node_annotation, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        subgraph_builder.add_node(
            "critic", 
            self._node_critic, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        subgraph_builder.add_node(
            "finalize", 
            self._node_finalize, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        subgraph_builder.add_node(
            "functional", 
            self._node_functional_characterization, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        #edges 
        subgraph_builder.add_edge(
            START, "annotation"
            )
        subgraph_builder.add_edge(
            "annotation", "critic"
            )
        subgraph_builder.add_conditional_edges(
            "critic",
            self._decfun_reflex_decision,
            {
                "finalize": "finalize", 
                "reflex": "annotation"
                }
        )
        subgraph_builder.add_conditional_edges(
            "finalize",
            self._decfun_strategy,
            {
                "functional": "functional", 
                "end": END
                }
        )
        subgraph_builder.add_edge("functional", END)
        #compile
        subgraph = subgraph_builder.compile(checkpointer=MemorySaver())
        return subgraph

    def _init_graph(self):
        """Build Cell# agent stategraph"""
        graph_builder = StateGraph(MainGraphState)
        #nodes
        graph_builder.add_node(
            "get_metadata", 
            self._node_get_metadata, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        graph_builder.add_node(
            "get_targetcell", 
            self._node_get_target_celltypes, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        graph_builder.add_node(
            "scrape_markers", 
            self._node_scrape_markers, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        graph_builder.add_node(
            "get_expression", 
            self._node_get_expresssummary, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        graph_builder.add_node(
            "annotation_subgraph", 
            self._node_annotation_mapped, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        graph_builder.add_node(
            "normalize_celltype", 
            self._node_normalize_celltype, 
            retry=RetryPolicy(max_attempts=self.max_retry)
            )
        #edges
        graph_builder.add_edge(
            START, 
            "get_metadata"
            )
        graph_builder.add_edge(
            "get_metadata", 
            "get_targetcell"
            )
        graph_builder.add_conditional_edges(
            "get_targetcell",
            self._decfun_router,
            {
                "scrape markers": "scrape_markers", 
                "skip scrape": "get_expression"}
                )
        graph_builder.add_edge(
            "scrape_markers", 
            "get_expression"
            )
        graph_builder.add_conditional_edges(
            "get_expression",
            self._map_annotation,
            ["annotation_subgraph"]
            )
        graph_builder.add_edge(
            "annotation_subgraph", 
            "normalize_celltype")
        graph_builder.add_edge(
            "normalize_celltype", 
            END)
        #compile
        graph = graph_builder.compile(checkpointer=MemorySaver())
        return graph
    
    def run(
            self,
            llm,
            adata: AnnData,
            thread_id: str = '1',
            plot_annotation: bool = True,
            cluster_key: str = "leiden",
            cell_marker_df_dir: str = "",
            max_iter: int = 5,
            ):
        """
        Run the Cell# agent to perform cell type annotation.

        Parameters:
        - llm: The language model used for annotation. Must be compatible with the agent's requirements.
        - adata (AnnData): AnnData object containing single-cell RNA sequencing data.
        - thread_id (str): Thread identifier for the graph. Default is '1'.
        - plot_annotation (bool): Whether to plot the annotation results. Default is True.
        - cluster_key (str): Column name in adata.obs for clustering. Default is 'leiden'.
        - cell_marker_df_dir (str): Directory path to the cell marker dataframe. Default is an empty string.
        - max_iter (int): Maximum number of iterations for annotation. Default is 5.

        Returns:
        - output_adata (AnnData): Annotated AnnData object.
        - agent_res (dict): Result of the agent's execution.

        Raises:
        - ValueError: If input parameters are invalid (e.g., adata type, cluster_key, or max_iter).
        - RuntimeError: If the agent fails to execute or output is invalid.
        """
        # Validate input parameters
        if not isinstance(adata, AnnData):
            raise ValueError("adata must be an instance of AnnData.")
        if cluster_key not in adata.obs.columns:
            raise ValueError(f"Cluster key '{cluster_key}' not found in adata.obs.")
        if max_iter < 1:
            raise ValueError("max_iter must be at least 1.")

        # Configure the thread
        config = {"configurable": {"thread_id": thread_id}}

        #Solving adata unserializability problem with pickle
        adata_dir = "adata_temp.pkl"
        with open(adata_dir, "wb") as f:
            pickle.dump(adata, f, protocol=pickle.HIGHEST_PROTOCOL)
        #run agent
        agent_res = self.graph.invoke(
            input={
                "anno_llm": llm,
                "max_iter": max_iter,
                "adata_dir": adata_dir,
                "cluster_key": cluster_key,
                "maker_df_dir": cell_marker_df_dir,
            },
            config=config
        )

        # Safely extract the output AnnData object
        # Plot the annotation if requested, with error handling
        if plot_annotation:
            try:
                with open(adata_dir, "rb") as f:
                    output_adata = pickle.load(f)

                if 'umap' not in output_adata.uns:
                    print('Calculate umap before plotting...')
                    sc.pp.pca(output_adata)
                    sc.pp.neighbors(output_adata)
                    sc.tl.umap(output_adata)
                sc.pl.umap(output_adata, color=[
                                                'leiden', 
                                                'Cell#', 
                                                'Cell#_raw',
                                                'Cell#_funcgroup'
                                                ], ncols=1)
            except Exception as e:
                print(f"Warning: Failed to plot annotation: {e}")

        return agent_res


    #================================================================
    # Defination of nodes and dicision funcionson of Cell# subgraph
    #================================================================

    #Define nodes for subgraph
    def _node_annotation(self,state: SubGraphState):
        #pass parameters
        llm = state["anno_llm"]
        cluster = state["cluster"]
        strategy = state["anno_strategy"]
        exp_summary_dict = state["exp_summary_dict"]
        metadata_dict = state["metadata_dict"]
        cell_markers_table = state["cell_markers_table"]
        critique = state["anno_critique"]
        n_iter = state["n_iter"]
        #convert to markdown table
        exp_summary_table = exp_summary_dict[cluster]
        metadata_table = metadata_dict[cluster]
        #convert critique
        if len(state["anno_critique"]) > 1 :
            critique = "\nYou and your coworkers are collaborating on multiple rounds of annotations and corrections, and your coworkers will be evaluating your previous annotations, if not the first round; consider their evaluations before you annotate:\n" + critique
        #set up instructions for different strategies
        if strategy.lower() == 'secondary':
            instruction = "Since the current annotation is aimed at subpopulations of specific cell types that are very case specific, you do not necessarily have to adhere to the given cell types and their markers. But please still respect the given hierarchy of reference cell types as much as possible."
        else:
            instruction = "Since the current annotation is aimed at the whole population of cell types, you should adhere to the given cell types and their markers as much as possible."
        #prompting

        #build chain
        prompt = PromptTemplate(
            input_variables=[
                "exp_summary_table", 
                "metadata_table", 
                "cell_markers_table", 
                "instruction", 
                "critique"],
            template=annotation_prompt
        )
        chain = prompt | llm
        #call llm
        print(f"Annotating cluster {cluster}...")
        i = 0
        while i < 3:
            try:
                response = chain.invoke({
                    "exp_summary_table": exp_summary_table,
                    "metadata_table": metadata_table,
                    "cell_markers_table": cell_markers_table,
                    "instruction": instruction,
                    "critique": critique
                })
                #parse response
                cell_type = parse_jsonfromcontent(response.content)
                cell_type = cell_type[0]
                break
            except:
                i+=1
        #recod interation
        n_iter += 1
        return {
            "anno_response": response.content,
            "anno_celltype": cell_type,
            "n_iter": n_iter,
        }

    def _node_critic(self, state: SubGraphState):
        #pass parameters
        llm = state["anno_llm"]
        cluster = state["cluster"]
        cell_type = state["anno_celltype"]
        draft_response_wreason = state["anno_response"]
        exp_summary_dict = state["exp_summary_dict"]
        metadata_dict = state["metadata_dict"]
        cell_markers_table = state["cell_markers_table"]
        #convert to markdown table 
        exp_summary_table = exp_summary_dict[cluster]
        metadata_table = metadata_dict[cluster]
        #prompting
        
        #build chain
        prompt = PromptTemplate(
            input_variables=[
                "cell_type", 
                "exp_summary_table", 
                "metadata_table", 
                "draft_response_wreason", 
                "cell_markers_table"],
            template=annotation_critic_prompt
        )
        chain = prompt | llm 
        #call llm
        print(f"Checking annotation for cluster {cluster}...")
        response = chain.invoke({
            "cell_type": cell_type,
            "exp_summary_table": exp_summary_table,
            "metadata_table": metadata_table,
            "draft_response_wreason": draft_response_wreason,
            "cell_markers_table": cell_markers_table
        })
        #parse response
        decision_dic = parse_jsonfromcontent(response.content)
        decision = decision_dic["final decision"]
        return {
            "anno_critique": response.content,
            "critic_decision": decision,
        }

    def _node_finalize(self, state: SubGraphState):

        cluster = state["cluster"]
        cell_type = state["anno_celltype"]
        anno_response = state["anno_response"]
        functional_anno = "not applied"
        finnal_result = {
            "cluster": cluster,
            "cell type": cell_type,
            "functional group": functional_anno,
            "reason": anno_response,
        }
        print("Final annotation of",cluster,"is",cell_type)
        return {
            "anno_result": finnal_result,
        }
        
    def _node_functional_characterization(self, state: SubGraphState):
        #pass parameters
        llm = state["anno_llm"]
        cluster = state["cluster"]
        exp_summary_dict = state["exp_summary_dict"]
        metadata_dict = state["metadata_dict"]
        cell_type = state["anno_celltype"]
        anno_result = state["anno_result"]
        #convert to markdown table
        exp_summary_table = exp_summary_dict[cluster]
        metadata_table = metadata_dict[cluster]
        #prompting

        #build chain
        prompt = PromptTemplate(
            input_variables=[
                "cell_type", 
                "exp_summary_table", 
                "metadata_table"],
            template=functional_prompt
        )
        chain = prompt | llm | JsonOutputParser()
        #call llm
        print(f"Functional characterization for cluster {cluster}...")
        i=0
        while i < 3:
            try:
                response = chain.invoke({
                    "cell_type": cell_type,
                    "exp_summary_table": exp_summary_table,
                    "metadata_table": metadata_table,
                })
                break
            except:
                i+=1
        #parse response
        functional_anno = response
        anno_result["functional group"] = str(functional_anno)
        return {
            "anno_result": anno_result,
        }

    #----------------------------------------------------------------
    #Define decision functions for subgraph
    def _decfun_reflex_decision(self, state: SubGraphState):
        n_iter = state["n_iter"]
        cluster = state["cluster"]
        max_iter = state["max_iter"]
        decision = state["critic_decision"]
        if n_iter >= max_iter:
            print(f"Maximum number of annotation iterations reached for cluster {cluster}.")
            return "finalize"
        else:
            if decision.lower() == "approved":
                print(f"Annotation result for cluster {cluster} is satisfied.")
                return "finalize"
            else:
                print(f"Annotation result for cluster {cluster} is not yed satisfied, for round",n_iter)
                return "reflex"

    def _decfun_strategy(self, state: SubGraphState):
        strategy = state["anno_strategy"]
        if strategy.lower() == "secondary":
            return "functional"
        else:
            return "end"

    #================================================================
    # Defination of state, nodes and dicision funcionson of Cell# maingraph
    #================================================================
    #Define nodes for maingraph
    def _node_get_metadata(self, state:MainGraphState):
        """
        Extract useful metadata columns from an AnnData object for cell type annotation using a language model (LLM).
        
        This function:
        1. Generates a summary of the AnnData object.
        2. Uses an LLM to select metadata columns relevant to cell type annotation.
        3. Summarizes the selected metadata for the entire dataset and per cluster.
        
        Parameters:
        - adata_dir (str): pickle dir for AnnData object containing single-cell RNA sequencing data.
        - llm: Language model instance used to select metadata columns.
        - group (str): Column name in adata.obs for clustering (default: 'leiden').
        
        Returns:
        - useful_meta_cols (list): List of metadata column names selected by the LLM.
        - metadata_summary (str): Summary of selected metadata columns for the entire dataset.
        - metadata_dict (dict): Summaries of selected metadata columns for each cluster.
        
        """
        #--------------------------------
        #pass parameters
        llm = state["anno_llm"]
        group = state["cluster_key"]
        adata_dir = state["adata_dir"]
        with open(adata_dir, "rb") as f:
            adata = pickle.load(f)

        #--------------------------------
        #data presception, step1, get over all presception
        print("Getting summary of given data...")
        data_type, adata_summary = data_perception(adata)
        print("given data is",data_type)
        #--------------------------------
        #call for llm
        prompt = PromptTemplate(
            input_variables = ["adata_summary"],
            template = chose_column_prompt,
        )
        chain =  prompt | llm | JsonOutputParser()
        i = 0 
        while i<3:
            try:
                meta_cols =  chain.invoke({"adata_summary": adata_summary})
                break
            except:
                i+=1

        #--------------------------------
        #data presception, step2, get detailed presception of each column, for whole data and each cluster
        print("Collecting data metadata summary...")
        metadata_summary =  get_dfcol_summaries(adata.obs, meta_cols)
        metadata_dict = {}
        for cluster in adata.obs[group].unique():
            metadata_dict[cluster] = get_dfcol_summaries(adata[adata.obs[group] == cluster].obs, meta_cols)

        

        return {
            "metadata_summary": metadata_summary,
            "metadata_dict": metadata_dict,
        }

    def _node_get_target_celltypes(self, state:MainGraphState):
        #--------------------------------
        #pass parameters
        llm = state["anno_llm"]
        metadata_summary = state["metadata_summary"]
        maker_df_dir = state["maker_df_dir"]
        #--------------------------------
        #call for llm
        
        prompt = PromptTemplate(
            input_variables = ["metadata_summary"],
            template = chose_celltype_prompt,
        )
        chain =  prompt | llm | JsonOutputParser()
        i = 0
        print("Looking for target cell types for annotation...")
        while i < 3:
            try:
                response =  chain.invoke({"metadata_summary": metadata_summary})
                #--------------------------------
                #parse parameters
                strategy = response["annotation strategy"]
                cell_types = response["cell_types"]
                break
            except:
                i+=1
        cell_types_str = "Recommended annotation target cell types are:\n"
        for cell in cell_types:
            cell_types_str += cell + '\n'
        print(cell_types_str)

        #--------------------------------
        #trying to use provided cell markers
        try:
            marker_df = pd.read_csv(maker_df_dir)
            print("Cell marker dataframe loaded.")
            try:
                cell_markers_table = df2markdownTable(marker_df)
                marker_df.to_csv('scraped_cell_markers.csv', encoding="utf-8-sig", index=False)
                marker_offered = True
            except:
                print("Failed to convert cell marker dataframe to markdown.")
                marker_offered = False
                cell_markers_table = ""
        except:
            marker_offered = False
            cell_markers_table = ""

        return {
            "anno_strategy": strategy,
            "target_cell_types": cell_types,
            "marker_offered":marker_offered,
            "cell_markers_table": cell_markers_table,
        }

    def scrape_markers(
            self,
            cell_type, 
            llm, 
            query,
            ):
        """
        Scrape and retrieve marker genes for a given cell type using web search results and a language model (LLM).

        This function:
        1. Performs a web search based on the cell type and query.
        2. Formats the search results into a readable string.
        3. Uses a language model to recall and refine marker genes based on the search results.
        4. Returns the LLM's full response and the extracted list of markers.

        Parameters:
        - llm: Language model instance used to process and refine the marker list.
        - cell_type (str): The cell type for which marker genes are being retrieved (e.g., "T-cell").
        - query (str): The search query to retrieve relevant web content (e.g., "marker genes").

        Returns:
        - response_content (str): The complete response from the LLM, including its thought process.
        - markers (list): A list of marker genes extracted from the LLM's response in JSON format.
        """
        #web scraping 
        print(f"Trying to fetch cell markers for {cell_type} from web.")
        try:
            web_res = self.web_retriever.invoke(cell_type + ' ' + query)
            #parse search result
            search_res = '============\n'
            for i, doc in enumerate(web_res, start=1):
                search_res += f"Web page {i}:\n{doc.page_content}\n\n"
        except:
            print("Web search failed")
            search_res = "Web search failed, please use your own memory and knowledge about cell types and thire markers."
        #process search result
        
        #build chain
        prompt = PromptTemplate(
            input_variables = ["cell_types", "search_results"],
            template = get_markers,
        )
        chain = prompt | llm 
        
        #invoke llm
        response =  chain.invoke(
            {
                "cell_type": cell_type,
                "search_results": search_res,
            })
        #convert to python list
        markers = parse_jsonfromcontent(response.content)
        
        return response.content, markers

    def _node_scrape_markers(self, state: MainGraphState):
        """
        Scrapes cell type markers based on provided metadata and cell types.
        
        This function uses a language model to generate a search query prefix from the metadata summary.
        It then scrapes markers for each target cell type using this query in parallel.
        The results are saved to a CSV file and returned as a markdown table.
        
        Parameters:
        state (MainGraphStat): A state object containing necessary parameters.
            - anno_llm: The language model for annotation.
            - metadata_summary: Summary of metadata from collected data.
            - target_cell_types: List of cell types to scrape markers for.
        
        Returns:
        dict: A dictionary containing the markdown table of cell types and their markers.
        """
        #--------------------------------
        #parse parameters
        llm = state["anno_llm"]
        metadata_summary = state["metadata_summary"]
        cell_types = state["target_cell_types"]
        print("Scraping cell markers...")

        #--------------------------------
        #generate search query
        
        prompt = PromptTemplate(
            input_variables = ["metadata_summary"],
            template = search_query_prompt,
        )
        query_chain = prompt | llm | StrOutputParser()
        query = query_chain.invoke({"metadata_summary": metadata_summary})

        #--------------------------------
        #scape cell markers in parallel
        process_marker_scrape = partial(
            self.scrape_markers,
            llm = llm, 
            query = query,
            )
        
        all_dfs = []
        errors = []
        with ThreadPoolExecutor() as executor:
            futures = {
                executor.submit(process_marker_scrape, cell_type):cell_type for cell_type in cell_types}
            for future in as_completed(futures):
                cell_type = futures[future]
                try:
                    reason, markers = future.result()
                    df = pd.DataFrame([{
                        "cell_type": cell_type,
                        "markers": markers,
                        "reason": reason,
                    }])
                    all_dfs.append(df)
                except Exception as exc:
                    errors.append((cell_type, exc))
                    #print(f'{cell_type} generated an exception: {exc}')
        # print errors if there are any
        if errors:
            print("The following cell types had errors during scraping:")
            for cell_type, exc in errors:
                print(f"{cell_type}: {exc}")

        #--------------------------------
        #parse result and save to csv
        cell_markers_df = pd.concat(all_dfs,ignore_index=True)
        cell_markers_df.to_csv("scraped_cell_markers.csv", encoding="utf-8-sig", index=False)
        print("Cell type and marker list saved to csv.")
        cell_markers_table = df2markdownTable(cell_markers_df[['cell_type','markers']])
        return {
            "cell_markers_table":cell_markers_table,
        }

    def _node_get_expresssummary(self, state: MainGraphState):
        """
        Generates expression summaries for clusters in a single-cell RNAseq dataset.
        
        This function processes the AnnData object to extract marker genes and highly variable genes (HVGs)
        for each cluster. It then computes expression summaries for these genes in each cluster.
        
        Parameters:
        state (MainGraphStat): A state object containing necessary parameters.
            - adata_dir: pickle file dir for AnnData object containing the single-cell RNAseq data.
            - cluster_key: The key in adata.obs that defines the cluster assignments.
        
        Returns:
        dict: A dictionary containing:
            - clusters: List of unique cluster identifiers.
            - exp_summary_dict: A dictionary with clusters as keys and their expression summaries as values.
        """
        import ast
        import scanpy as sc
        #--------------------------------
        #parse parameters
        adata_dir = state["adata_dir"]
        with open(adata_dir, "rb") as f:
            adata = pickle.load(f)
        group = state["cluster_key"]
        clusters = adata.obs[group].unique().tolist()
        print("Getting data gene expressing summary...")

        #--------------------------------
        #get cell markers 
        cell_markers_df = pd.read_csv("scraped_cell_markers.csv")
        marker_genes = []
        for _, row in cell_markers_df.iterrows():
            if type(row['markers']) == list:
                marker_genes += row['markers']
            elif type(row['markers']) == str:
                marker_genes += ast.literal_eval(row['markers'])

        #--------------------------------
        #get hvgs for each cluster
        if 'rank_genes_groups' not in adata.uns:
            sc.tl.rank_genes_groups(adata, groupby=group)
        hvgs = []
        for clst in clusters:
            hvgs += list(adata.uns['rank_genes_groups']['names'][clst][:5])
        gene_list = list(set(marker_genes + hvgs))

        #--------------------------------
        #get expression summary
        exp_summary_dict = {}
        for clst in clusters:
            mask = adata.obs[group] == clst
            exp_sum = get_exp_summary(adata[mask],gene_list)
            exp_summary_dict[clst] = exp_sum

        return {
            "clusters":clusters,
            "exp_summary_dict":exp_summary_dict,
        }
        
    def _node_annotation_mapped(self, state: MapGraphState):
        subgraph_input = {
            #pars
            "anno_llm": state["anno_llm"],
            "max_iter" : state["max_iter"],
            #input
            "cluster" : state["cluster"],
            "anno_strategy" : state["anno_strategy"],
            "cell_markers_table" : state["cell_markers_table"],
            "exp_summary_dict": state["exp_summary_dict"],
            "metadata_dict": state["metadata_dict"],
            #sub graph only
            "anno_critique" :"",
            "n_iter":0
        }
        config = {"configurable": {"thread_id": "1"}}
        print("Calling subgraph for annotation...")
        #call subgraph
        subgraph_res = self.subgraph.invoke(subgraph_input, config=config)

        return {"anno_results":[subgraph_res['anno_result']]}

    def _node_normalize_celltype(self, state: MainGraphState):
        #pass parameters
        llm = state["anno_llm"]
        metadata_summary = state["metadata_summary"]
        anno_results = state["anno_results"]
        adata_dir = state["adata_dir"]
        with open(adata_dir, "rb") as f:
            adata = pickle.load(f)
        print("Normalizing major cell type annotations...")
        #convert annotation result to dataframe
        res_df_list = []
        for res_dic in anno_results:
            df_temp = pd.DataFrame([res_dic])
            res_df_list.append(df_temp)
        anno_results_df = pd.concat(res_df_list,ignore_index=True)
        anno_results_df.to_csv('AnnoResDF.csv')
        print('Raw annotation result saved as csv.')
        #get unique cell types
        annotated_cell_types = anno_results_df["cell type"].unique().tolist()
        #call llm
        
        #build chain
        prompt = PromptTemplate(
            input_variables=["metadata_summary", "annotated_cell_types"],
            template=normaliztion_prompt
        )
        anno_results_df['norm. cell type'] = anno_results_df["cell type"]
        i = 0
        while i < 3:
            try:
                chain = prompt | llm | JsonOutputParser()
                response = chain.invoke({
                    "metadata_summary": metadata_summary,
                    "annotated_cell_types": annotated_cell_types
                })
                #get back to dataframe
                anno_results_df['norm. cell type'] = anno_results_df['norm. cell type'].map(response)
                break
            except:
                i+=1
        #save to csv 
        
        
        anno_results_df.to_csv('AnnoResDF.csv')
        print('Normalized annotation result saved as csv.')
        #convert to adata 
        anno_results_df['cluster'] = anno_results_df['cluster'].astype(str)
        anno_results_df['functional group'] = anno_results_df['functional group'].astype(str)
        temp_df = anno_results_df.copy().set_index('cluster')
        anno_dic_raw = temp_df['cell type'].to_dict()
        anno_dic= temp_df['norm. cell type'].to_dict()
        anno_dic_fun = temp_df['functional group'].to_dict()
        #get back to adata
        adata.obs["Cell#"] = adata.obs["leiden"]
        adata.obs["Cell#"] = adata.obs["Cell#"].map(anno_dic)
        print('Normalized cell type annotated.')
        adata.obs["Cell#_raw"] = adata.obs["leiden"]
        adata.obs["Cell#_raw"] = adata.obs["Cell#_raw"].map(anno_dic_raw)
        print('Raw cell type annotated.')
        adata.obs["Cell#_funcgroup"] = adata.obs["leiden"]
        adata.obs["Cell#_funcgroup"] = adata.obs["Cell#_funcgroup"].map(anno_dic_fun)
        print('Functional group annotated.')
        #save to pickle, it load faster
        with open(adata_dir, "wb") as f:
            pickle.dump(adata, f, protocol=pickle.HIGHEST_PROTOCOL)
        #save annotated data
        print("Saving Annotated adata to .h5ad file.")
        adata.write_h5ad('Annotated_adata.h5ad')
            
    #----------------------------------------------------------------
    #Define decision functions for subgraph
    def _decfun_router(self, state:MainGraphState):
        marker_offered = state["marker_offered"]
        if marker_offered:
            return "scrape markers"
        else:
            return "skip scrape"
        
    #----------------------------------------------------------------
    #Define map-reduce functions for subgraph
    def _map_annotation(self, state:MainGraphState):
        #return a list of `Send` objects, each `Send` object consists of the name of a node in the graph
        return [Send("annotation_subgraph", {
            "anno_llm": state["anno_llm"],
            "max_iter": state["max_iter"],
            "anno_strategy": state["anno_strategy"],
            "cell_markers_table": state["cell_markers_table"],
            "exp_summary_dict": state["exp_summary_dict"],
            "metadata_dict": state["metadata_dict"],
            "cluster":s,
            }) for s in state["clusters"]]

